---
phase: 05-domain-event-publishing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - docker-compose.yaml
  - src/application/event_bus.py
  - tests/unit/application/test_event_bus.py
autonomous: true

must_haves:
  truths:
    - "Event bus can register handlers for specific event types"
    - "Event bus can dispatch events to registered handlers"
    - "Multiple handlers can subscribe to the same event type"
    - "Procrastinate library is available for import"
    - "Job queue database exists in development environment"
  artifacts:
    - path: "src/application/event_bus.py"
      provides: "In-process event bus with handler registry"
      exports: ["register", "publish", "publish_all", "clear_handlers"]
    - path: "tests/unit/application/test_event_bus.py"
      provides: "Unit tests for event bus"
      min_lines: 50
  key_links:
    - from: "event_bus.publish"
      to: "registered handlers"
      via: "_handlers dict lookup"
      pattern: "_handlers\\.get\\(type\\(event\\)"
---

<objective>
Create the foundational event bus infrastructure and add job queue dependencies.

Purpose: Establish the in-process event bus that will dispatch domain events to handlers after UoW commit. This is the foundation for event-driven architecture - handlers subscribe to events, and the bus delivers them.

Output:
- Event bus module with register/publish API
- Procrastinate + psycopg dependencies added
- Jobs database in docker-compose for development
- Unit tests proving event bus works
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/CHECKPOINTS.md
@.planning/phases/05-domain-event-publishing/05-CONTEXT.md
@.planning/phases/05-domain-event-publishing/05-RESEARCH.md

# Existing files to understand patterns
@src/domain/events/base.py
@src/domain/events/user_events.py
@src/adapters/logging/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependencies and jobs database</name>
  <files>
    - pyproject.toml
    - docker-compose.yaml
  </files>
  <action>
1. Add procrastinate and psycopg[binary] to pyproject.toml dependencies:
   - `"procrastinate>=3.5.0"`
   - `"psycopg[binary]>=3.2.0"` (required by PsycopgConnector)

2. Add jobs PostgreSQL database to docker-compose.yaml:
   - New service `postgres-jobs` using same postgres:16 image
   - Volume `postgres-jobs-data` for persistence
   - Environment: POSTGRES_USER=postgres, POSTGRES_PASSWORD=postgres, POSTGRES_DB=jobs
   - Healthcheck same pattern as main postgres
   - Port 5433:5432 (different host port to avoid conflict)
   - Same network (app-network)

3. Add JOB_QUEUE_DATABASE_URL environment variable to app service:
   - `JOB_QUEUE_DATABASE_URL=postgresql://postgres:postgres@postgres-jobs:5432/jobs`

4. Run `uv sync` to install new dependencies.

Note: Use separate database as per CONTEXT.md decision ("Separate database for job queue, not same as app database").
  </action>
  <verify>
    - `python -c "import procrastinate; print(procrastinate.__version__)"` succeeds
    - `python -c "import psycopg; print(psycopg.__version__)"` succeeds
    - `docker compose config` validates without errors
  </verify>
  <done>
    - Procrastinate and psycopg are importable
    - docker-compose.yaml has postgres-jobs service on port 5433
    - JOB_QUEUE_DATABASE_URL is defined in app service environment
  </done>
</task>

<task type="auto">
  <name>Task 2: Create event bus module</name>
  <files>
    - src/application/__init__.py (create if needed)
    - src/application/event_bus.py
  </files>
  <action>
1. Create `src/application/__init__.py` if it doesn't exist (empty or minimal).

2. Create `src/application/event_bus.py` implementing the Cosmic Python pattern:

```python
"""In-process event bus for domain event publishing.

The event bus dispatches domain events to registered handlers after
UoW commit. Handlers are called synchronously. For async or
potentially-failing operations (email, external API), handlers
should enqueue jobs to the job queue.

Usage:
    from src.application import event_bus
    from src.domain.events.user_events import UserRegistered

    def on_user_registered(event: UserRegistered) -> None:
        # Enqueue welcome email job
        pass

    event_bus.register(UserRegistered, on_user_registered)

    # Later, after UoW commit:
    event_bus.publish_all(events)
"""
```

Key implementation details:
- `_handlers: dict[type, list[Callable[..., Any]]] = {}` for registry
- `register(event_type: type, handler: Callable) -> None` appends to list
- `publish(event: Any) -> None` calls all handlers for event type
- `publish_all(events: list[Any]) -> None` iterates and publishes
- `clear_handlers() -> None` for testing cleanup
- Use structlog logger for debug/info logging (handler_registered, handling_event)
- On handler exception: log with exception(), then re-raise (fail fast in dev)
- No PII in logs - only event_type and handler name

Follow the exact pattern from 05-RESEARCH.md "Complete Event Bus Implementation" section.
  </action>
  <verify>
    - `python -c "from src.application.event_bus import register, publish, publish_all, clear_handlers"` succeeds
    - `ruff check src/application/event_bus.py` passes
    - `mypy src/application/event_bus.py` passes
  </verify>
  <done>
    - Event bus module exists with register/publish/publish_all/clear_handlers exports
    - Type hints are complete
    - Logging uses structlog pattern from project
  </done>
</task>

<task type="auto">
  <name>Task 3: Unit tests for event bus</name>
  <files>
    - tests/unit/application/__init__.py (create if needed)
    - tests/unit/application/test_event_bus.py
  </files>
  <action>
1. Create test directory structure if needed.

2. Create comprehensive unit tests for event bus:

Test cases:
- `test_register_handler_for_event_type` - handler is stored in registry
- `test_publish_calls_registered_handler` - publish invokes handler with event
- `test_publish_to_multiple_handlers` - all handlers called in order
- `test_publish_unregistered_event_type` - no error, just no handlers
- `test_clear_handlers` - registry is empty after clear
- `test_publish_all_dispatches_multiple_events` - each event goes to its handlers
- `test_handler_exception_propagates` - exception re-raised after logging

Use pytest fixtures:
- `@pytest.fixture(autouse=True)` to call `clear_handlers()` after each test (isolation)
- Simple dataclass events for testing (not real domain events)

Example test event:
```python
@dataclass(frozen=True)
class TestEvent:
    value: str
```

Verify handler invocation using a list collector or mock.
  </action>
  <verify>
    - `pytest tests/unit/application/test_event_bus.py -v` all tests pass
    - At least 7 test cases exist
  </verify>
  <done>
    - All unit tests pass
    - Tests cover registration, publishing, multiple handlers, error propagation
    - Test isolation via clear_handlers fixture
  </done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Dependencies installed:
   ```bash
   python -c "import procrastinate; import psycopg; print('OK')"
   ```

2. Event bus functional:
   ```bash
   pytest tests/unit/application/test_event_bus.py -v
   ```

3. Docker compose valid:
   ```bash
   docker compose config --quiet && echo "Valid"
   ```

4. All existing tests still pass:
   ```bash
   pytest tests/ -x -q
   ```
</verification>

<success_criteria>
1. Procrastinate 3.5+ and psycopg 3.x are installed and importable
2. docker-compose.yaml includes postgres-jobs service with JOB_QUEUE_DATABASE_URL
3. src/application/event_bus.py exports register, publish, publish_all, clear_handlers
4. Event bus unit tests pass (7+ test cases)
5. All existing tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-domain-event-publishing/05-01-SUMMARY.md`
</output>
