---
phase: 04.1-test-schema-parity
plan: 02
type: execute
wave: 2
depends_on: ["04.1-01"]
files_modified:
  - tests/integration/test_schema_parity.py
  - CLAUDE.md
  - .claude/skills/safe-schema-change.md
  - .planning/PROJECT.md
  - .planning/CHECKPOINTS.md
autonomous: true

must_haves:
  truths:
    - "Editing tables.py without generating a migration causes a test failure"
    - "CLAUDE.md contains autogenerate-first workflow rules visible to every Claude session"
    - "A step-by-step schema change procedure exists as a skill document"
    - "PROJECT.md records the autogenerate-first migration workflow decision"
  artifacts:
    - path: "tests/integration/test_schema_parity.py"
      provides: "Drift detection integration test using compare_metadata()"
      contains: "compare_metadata"
    - path: "CLAUDE.md"
      provides: "Autogenerate-first rules for Claude agents"
      contains: "autogenerate"
    - path: ".claude/skills/safe-schema-change.md"
      provides: "Step-by-step schema change procedure"
      contains: "alembic revision --autogenerate"
    - path: ".planning/PROJECT.md"
      provides: "Autogenerate-first decision record"
      contains: "autogenerate-first"
  key_links:
    - from: "CLAUDE.md"
      to: ".claude/skills/safe-schema-change.md"
      via: "reference to skill file"
      pattern: "safe-schema-change"
    - from: "tests/integration/test_schema_parity.py"
      to: "alembic/versions/"
      via: "alembic upgrade head in fixture"
      pattern: "command\\.upgrade"
---

<objective>
Add a drift detection integration test that fails when SQLAlchemy metadata and Alembic migrations diverge, and encode the autogenerate-first workflow into project documentation so future development never re-introduces schema drift.

Purpose: The migration rework (Plan 01) fixed the immediate drift. This plan prevents drift from ever returning by adding a test guard and encoding the correct workflow into CLAUDE.md, a skill file, and PROJECT.md. Three reinforcement layers ensure agents and developers always follow the autogenerate-first approach.

Output: Drift detection test, updated CLAUDE.md with migration rules, schema change skill file, updated PROJECT.md with migration decision.
</objective>

<execution_context>
@./.claude/agents/gsd-executor.md
@./.claude/agents/gsd-summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/CHECKPOINTS.md
@.planning/phases/04.1-test-schema-parity/04.1-CONTEXT.md
@.planning/phases/04.1-test-schema-parity/04.1-RESEARCH.md
@.planning/phases/04.1-test-schema-parity/04.1-01-SUMMARY.md
@CLAUDE.md
@tests/integration/conftest.py
@src/adapters/persistence/orm/base.py
@src/adapters/persistence/orm/tables.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add drift detection integration test</name>
  <files>
    tests/integration/test_schema_parity.py
  </files>
  <action>
    Create `tests/integration/test_schema_parity.py` with a test that programmatically verifies the Alembic migration chain produces the same schema as the SQLAlchemy metadata in tables.py.

    **Implementation:**
    1. Create a module-scoped fixture that:
       - Gets the test database URL from the existing `database_url` fixture (or reads TEST_DATABASE_URL env var)
       - Creates a SQLAlchemy engine
       - Drops and recreates the public schema (clean slate)
       - Runs `alembic upgrade head` via the Alembic command API (not CLI subprocess) with the test database URL
       - Yields the engine
       - Cleans up by dropping and recreating the public schema

    2. Create a test `test_migrations_match_metadata()` that:
       - Uses the migration engine fixture
       - Creates a `MigrationContext` from the connection
       - Calls `compare_metadata(migration_context, metadata)` from `alembic.autogenerate`
       - Asserts the diff list is empty
       - On failure, formats each diff tuple into a human-readable message so the developer knows exactly what drifted

    **Key imports:**
    ```python
    from alembic.autogenerate import compare_metadata
    from alembic.config import Config
    from alembic import command
    from alembic.migration import MigrationContext
    from sqlalchemy import create_engine, text
    from src.adapters.persistence.orm.base import metadata
    import src.adapters.persistence.orm.tables  # noqa: F401 -- registers tables
    ```

    **Important details:**
    - The fixture should use `scope="module"` to run migrations once per test module (not per test)
    - The test database URL should come from the `TEST_DATABASE_URL` env var (same as conftest.py)
    - The fixture must NOT interfere with other integration tests that use `metadata.create_all()`. It manages its own schema lifecycle (drop/create public schema before and after)
    - Set `compare_type=True` in the MigrationContext.configure() call to catch type mismatches
    - The test file should NOT import or use the session-scoped `setup_database` fixture from conftest.py -- it creates its own independent database state

    **What the test catches:**
    - Column added to tables.py but no migration generated
    - Column removed from tables.py but no migration generated
    - FK constraint in tables.py but missing from migration chain
    - Index in tables.py but missing from migration chain
    - Type mismatch between tables.py and migration chain
  </action>
  <verify>
    1. `pytest tests/integration/test_schema_parity.py -v` -- test passes (migrations match metadata)
    2. Temporarily add a dummy column to tables.py (e.g., `Column("_drift_test", String(10), nullable=True)` on the outbox table), then run the test again -- it MUST FAIL with a drift message. Remove the dummy column after verifying.
    3. `pytest tests/ -x -q` -- all tests pass (including the new drift test + all 407 existing tests)
  </verify>
  <done>
    Drift detection test exists at tests/integration/test_schema_parity.py. It catches both directions of drift (tables.py changes without migration, migration changes without tables.py). All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Encode autogenerate-first workflow in CLAUDE.md and skill file</name>
  <files>
    CLAUDE.md
    .claude/skills/safe-schema-change.md
  </files>
  <action>
    **Update CLAUDE.md:**
    Add a concise "Database Schema Changes" section with actionable rules. Keep it short (CLAUDE.md is always loaded, brevity matters). Add it after the existing "Checkpoint Validation" section.

    Rules to encode:
    - tables.py is the source of truth for database schema
    - Never hand-write DDL in migration files
    - Always use `alembic revision --autogenerate` to generate migrations from tables.py changes
    - After generating, review the migration -- hand-edit ONLY for data backfill logic
    - Run `alembic check` to verify no remaining drift
    - Run `alembic upgrade head` against the real database (not just tests)
    - Reference the skill file for the full step-by-step procedure
    - For the full procedure, see `.claude/skills/safe-schema-change.md`

    **Create `.claude/skills/safe-schema-change.md`:**
    Create the directory `.claude/skills/` if it doesn't exist. Write a non-interactive skill file (not a slash command) that codifies the complete safe schema change procedure.

    The skill file should contain:
    1. **When to use:** Any time a plan or task requires database schema changes (new tables, columns, indexes, FKs, type changes)
    2. **Procedure:**
       - Step 1: Make the change in `src/adapters/persistence/orm/tables.py`
       - Step 2: Run `alembic revision --autogenerate -m "description of change"`
       - Step 3: Review the generated migration file in `alembic/versions/`
       - Step 4: Hand-edit ONLY if the migration needs data backfill (e.g., populate a new NOT NULL column). Never hand-write DDL -- if autogenerate didn't produce the right DDL, fix tables.py
       - Step 5: Run `alembic check` to confirm no remaining drift
       - Step 6: Run `alembic upgrade head` to apply to the real database
       - Step 7: Run `alembic downgrade -1` then `alembic upgrade head` to verify reversibility
       - Step 8: Run `pytest tests/ -x -q` to confirm all tests pass
    3. **Common mistakes to avoid:**
       - Adding a column to tables.py but forgetting to generate a migration (drift test will catch this)
       - Writing DDL directly in a migration file instead of changing tables.py first
       - Using `metadata.create_all()` as proof that a schema change works (it bypasses Alembic)
    4. **Key files:**
       - Source of truth: `src/adapters/persistence/orm/tables.py`
       - Alembic config: `alembic/env.py`
       - Migration template: `alembic/script.py.mako`
       - Drift detection test: `tests/integration/test_schema_parity.py`
  </action>
  <verify>
    1. CLAUDE.md contains "Database Schema Changes" section with autogenerate-first rules
    2. `.claude/skills/safe-schema-change.md` exists with step-by-step procedure
    3. CLAUDE.md references the skill file path
  </verify>
  <done>
    CLAUDE.md has concise migration rules always visible to Claude agents. Skill file provides detailed procedure for schema changes. CLAUDE.md references the skill file.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update PROJECT.md and CHECKPOINTS.md with migration workflow decisions</name>
  <files>
    .planning/PROJECT.md
    .planning/CHECKPOINTS.md
  </files>
  <action>
    **Update PROJECT.md Key Decisions table:**
    Add a row to the Key Decisions table:
    | Autogenerate-first migration workflow | tables.py is source of truth; never hand-write DDL in migrations; use alembic revision --autogenerate; drift detection test guards parity | Validated (Phase 4.1) |

    **Update CHECKPOINTS.md:**
    Update the "After writing or modifying any Alembic migration" section to reflect the new autogenerate-first workflow:
    - Add rule: "Schema changes MUST start in tables.py, then use `alembic revision --autogenerate` to generate the migration"
    - Add rule: "Never hand-write DDL operations in migration files (if autogenerate doesn't produce the right DDL, fix tables.py)"
    - Add rule: "Run `alembic check` after generating migrations to confirm no remaining drift"
    - Update "Known Gaps" section to mark the schema drift gap as RESOLVED (the drift detection test now guards parity between metadata.create_all and alembic upgrade head)
  </action>
  <verify>
    1. PROJECT.md Key Decisions table includes autogenerate-first row
    2. CHECKPOINTS.md includes autogenerate-first rules in migration section
    3. CHECKPOINTS.md Known Gaps section reflects that schema drift is now guarded
  </verify>
  <done>
    PROJECT.md and CHECKPOINTS.md encode the autogenerate-first migration workflow decision, making it visible to all GSD planning and execution agents.
  </done>
</task>

</tasks>

<verification>
1. `pytest tests/integration/test_schema_parity.py -v` -- drift test passes
2. `pytest tests/ -x -q` -- all tests pass (407 existing + 1 new drift test = 408+)
3. CLAUDE.md has "Database Schema Changes" section
4. `.claude/skills/safe-schema-change.md` exists
5. PROJECT.md Key Decisions table has autogenerate-first entry
6. CHECKPOINTS.md has autogenerate-first rules
7. Temporarily introducing a drift in tables.py causes the drift test to fail (regression safety)
</verification>

<success_criteria>
- Drift detection test exists and passes when migrations match metadata
- Drift detection test fails when tables.py is modified without a corresponding migration
- CLAUDE.md, skill file, PROJECT.md, and CHECKPOINTS.md all encode the autogenerate-first workflow
- All tests pass (407 existing + new drift test)
</success_criteria>

<output>
After completion, create `.planning/phases/04.1-test-schema-parity/04.1-02-SUMMARY.md`
</output>
