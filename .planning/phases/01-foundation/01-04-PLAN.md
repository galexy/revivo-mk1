---
phase: 01-foundation
plan: 04
type: execute
wave: 3
depends_on: ["01-01", "01-02"]
files_modified:
  - src/adapters/__init__.py
  - src/adapters/persistence/__init__.py
  - src/adapters/persistence/orm/__init__.py
  - src/adapters/persistence/orm/base.py
  - src/adapters/persistence/orm/tables.py
  - src/adapters/persistence/orm/mappers.py
  - src/adapters/persistence/unit_of_work.py
  - alembic.ini
  - alembic/env.py
  - alembic/versions/001_initial_schema.py
autonomous: true

must_haves:
  truths:
    - "SQLAlchemy imperative mapping connects domain entities to database tables"
    - "Unit of Work implementation manages transaction boundaries"
    - "Outbox table exists for reliable domain event delivery"
    - "Alembic migration can create schema on fresh database"
    - "Domain models remain pure - no SQLAlchemy imports in src/domain/"
  artifacts:
    - path: "src/adapters/persistence/orm/tables.py"
      provides: "SQLAlchemy table definitions"
      contains: "Table"
    - path: "src/adapters/persistence/orm/mappers.py"
      provides: "Imperative mapping setup"
      contains: "map_imperatively"
    - path: "src/adapters/persistence/unit_of_work.py"
      provides: "SQLAlchemy UoW implementation"
      contains: "SqlAlchemyUnitOfWork"
    - path: "alembic/versions/001_initial_schema.py"
      provides: "Initial database migration"
      contains: "outbox"
  key_links:
    - from: "src/adapters/persistence/orm/mappers.py"
      to: "src/domain/model"
      via: "imports domain classes for mapping"
      pattern: "from src.domain.model"
    - from: "alembic/env.py"
      to: "src/adapters/persistence/orm/base.py"
      via: "imports metadata for migrations"
      pattern: "from src.adapters.persistence.orm"
---

<objective>
Create the persistence infrastructure layer with SQLAlchemy imperative mapping (Data Mapper pattern), Unit of Work implementation, outbox table for domain events, and Alembic migrations.

Purpose: Establish the database foundation that keeps domain models pure. Using imperative mapping instead of declarative ensures domain classes have no SQLAlchemy dependencies.

Output: Working persistence layer with migrations that can create the database schema from scratch.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SQLAlchemy table definitions and base</name>
  <files>
    src/adapters/__init__.py
    src/adapters/persistence/__init__.py
    src/adapters/persistence/orm/__init__.py
    src/adapters/persistence/orm/base.py
    src/adapters/persistence/orm/tables.py
  </files>
  <action>
Create SQLAlchemy table definitions following RESEARCH.md Data Mapper pattern:

1. **Package structure**:
   - src/adapters/__init__.py (empty)
   - src/adapters/persistence/__init__.py (empty)
   - src/adapters/persistence/orm/__init__.py (empty)

2. **src/adapters/persistence/orm/base.py**:
   ```python
   """SQLAlchemy base configuration."""
   from sqlalchemy import MetaData
   from sqlalchemy.orm import registry

   # Naming convention for constraints (helps with migrations)
   convention = {
       "ix": "ix_%(column_0_label)s",
       "uq": "uq_%(table_name)s_%(column_0_name)s",
       "ck": "ck_%(table_name)s_%(constraint_name)s",
       "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",
       "pk": "pk_%(table_name)s",
   }

   metadata = MetaData(naming_convention=convention)
   mapper_registry = registry(metadata=metadata)
   ```

3. **src/adapters/persistence/orm/tables.py**:
   Define foundation tables (actual entity tables added in later phases):

   ```python
   """SQLAlchemy table definitions."""
   from sqlalchemy import (
       Table, Column, String, Text, DateTime, Integer,
       Boolean, Numeric, ForeignKey, Index,
   )
   from datetime import datetime, UTC
   from .base import metadata

   # Outbox table for domain events (RESEARCH.md Pattern 5)
   outbox = Table(
       "outbox",
       metadata,
       Column("id", Integer, primary_key=True, autoincrement=True),
       Column("event_type", String(255), nullable=False),
       Column("aggregate_type", String(255), nullable=False),
       Column("aggregate_id", String(36), nullable=False),
       Column("payload", Text, nullable=False),  # JSON serialized
       Column("created_at", DateTime(timezone=True), nullable=False,
              default=lambda: datetime.now(UTC)),
       Column("processed_at", DateTime(timezone=True), nullable=True),
       Index("ix_outbox_unprocessed", "processed_at", postgresql_where=(Column("processed_at").is_(None))),
   )

   # Users table (foundation for all user-owned data)
   users = Table(
       "users",
       metadata,
       Column("id", String(36), primary_key=True),  # user_xxx
       Column("email", String(255), nullable=False, unique=True),
       Column("email_verified", Boolean, nullable=False, default=False),
       Column("created_at", DateTime(timezone=True), nullable=False,
              default=lambda: datetime.now(UTC)),
       Column("updated_at", DateTime(timezone=True), nullable=False,
              default=lambda: datetime.now(UTC), onupdate=lambda: datetime.now(UTC)),
   )

   # Encrypted secrets storage (for Plaid tokens, etc.)
   encrypted_secrets = Table(
       "encrypted_secrets",
       metadata,
       Column("id", Integer, primary_key=True, autoincrement=True),
       Column("user_id", String(36), ForeignKey("users.id"), nullable=False),
       Column("secret_type", String(50), nullable=False),  # e.g., "plaid_access_token"
       Column("encrypted_value", Text, nullable=False),  # AES-256-GCM encrypted
       Column("created_at", DateTime(timezone=True), nullable=False,
              default=lambda: datetime.now(UTC)),
       Column("updated_at", DateTime(timezone=True), nullable=False,
              default=lambda: datetime.now(UTC)),
       Index("ix_encrypted_secrets_user_type", "user_id", "secret_type", unique=True),
   )
   ```

Tables created:
- outbox: Domain event outbox for reliable delivery
- users: Foundation user table (expanded in later phases)
- encrypted_secrets: Storage for encrypted sensitive data

NOTE: Account and Transaction tables will be added in Phases 2 and 3.
  </action>
  <verify>
    - `grep "Table" src/adapters/persistence/orm/tables.py` shows table definitions
    - `grep "outbox" src/adapters/persistence/orm/tables.py` shows outbox table
    - `grep "encrypted_secrets" src/adapters/persistence/orm/tables.py` shows secrets table
  </verify>
  <done>
    - Base metadata with naming convention exists
    - Outbox table defined for domain events
    - Users table defined as foundation
    - Encrypted secrets table ready for sensitive data
  </done>
</task>

<task type="auto">
  <name>Task 2: Create imperative mapping and Unit of Work</name>
  <files>
    src/adapters/persistence/orm/mappers.py
    src/adapters/persistence/unit_of_work.py
    src/adapters/persistence/database.py
  </files>
  <action>
Create imperative mapping setup and UoW implementation:

1. **src/adapters/persistence/orm/mappers.py**:
   ```python
   """Imperative mapping between domain and ORM."""
   from .base import mapper_registry

   _mappers_started = False

   def start_mappers() -> None:
       """
       Initialize SQLAlchemy imperative mappings.
       Call once at application startup.

       Note: Currently no domain entities to map. Mappings will be added
       as entities are created in later phases (Account in Phase 2, etc.)
       """
       global _mappers_started
       if _mappers_started:
           return

       # Example mapping (commented until entities exist):
       # from src.domain.model.account import Account
       # from .tables import accounts
       # mapper_registry.map_imperatively(Account, accounts)

       _mappers_started = True

   def clear_mappers() -> None:
       """Clear all mappers. Used in tests."""
       global _mappers_started
       mapper_registry.dispose()
       _mappers_started = False
   ```

2. **src/adapters/persistence/database.py**:
   ```python
   """Database connection management."""
   from sqlalchemy import create_engine
   from sqlalchemy.orm import sessionmaker, Session
   from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
   from typing import Generator
   import os

   def get_database_url() -> str:
       """Get database URL from environment."""
       return os.getenv(
           "DATABASE_URL",
           "postgresql://postgres:postgres@postgres:5432/finance"
       )

   def get_async_database_url() -> str:
       """Get async database URL (asyncpg driver)."""
       url = get_database_url()
       return url.replace("postgresql://", "postgresql+asyncpg://")

   # Sync engine for migrations
   def create_sync_engine():
       return create_engine(get_database_url(), echo=False)

   # Async engine for API
   def create_async_engine_instance():
       return create_async_engine(get_async_database_url(), echo=False)

   # Session factories
   sync_session_factory = sessionmaker(bind=create_sync_engine())
   async_session_factory = async_sessionmaker(
       bind=create_async_engine_instance(),
       class_=AsyncSession,
       expire_on_commit=False,
   )

   def get_session() -> Generator[Session, None, None]:
       """Dependency for sync session (migrations, scripts)."""
       session = sync_session_factory()
       try:
           yield session
       finally:
           session.close()
   ```

3. **src/adapters/persistence/unit_of_work.py**:
   ```python
   """SQLAlchemy Unit of Work implementation."""
   from sqlalchemy.orm import Session, sessionmaker
   from sqlalchemy import insert
   from typing import Self
   from src.domain.events.base import DomainEvent
   from .orm.tables import outbox
   import json

   class SqlAlchemyUnitOfWork:
       """
       Unit of Work that manages transaction boundaries.
       Collects domain events and writes them to outbox in same transaction.
       """

       def __init__(self, session_factory: sessionmaker):
           self._session_factory = session_factory
           self._events: list[DomainEvent] = []

       def __enter__(self) -> Self:
           self._session: Session = self._session_factory()
           # Repositories will be added here as they're created
           return self

       def __exit__(self, exc_type, exc_val, exc_tb) -> None:
           if exc_type:
               self.rollback()
           self._session.close()

       @property
       def session(self) -> Session:
           """Access to underlying session for repositories."""
           return self._session

       def collect_events(self, events: list[DomainEvent]) -> None:
           """Collect domain events to be persisted with commit."""
           self._events.extend(events)

       def commit(self) -> None:
           """Commit transaction, writing events to outbox."""
           # Write collected events to outbox
           for event in self._events:
               self._session.execute(
                   insert(outbox).values(
                       event_type=event.event_type,
                       aggregate_type=event.aggregate_type,
                       aggregate_id=event.aggregate_id,
                       payload=json.dumps(event.to_dict(), default=str),
                   )
               )
           self._session.commit()
           self._events.clear()

       def rollback(self) -> None:
           """Rollback transaction and discard events."""
           self._session.rollback()
           self._events.clear()
   ```
  </action>
  <verify>
    - `grep "map_imperatively" src/adapters/persistence/orm/mappers.py` shows mapping setup
    - `grep "SqlAlchemyUnitOfWork" src/adapters/persistence/unit_of_work.py` shows UoW class
    - `grep "outbox" src/adapters/persistence/unit_of_work.py` shows event persistence
  </verify>
  <done>
    - Imperative mapping infrastructure ready (actual mappings added with entities)
    - Unit of Work manages transactions and event collection
    - Events persisted to outbox in same transaction as data
    - Database connection utilities created
  </done>
</task>

<task type="auto">
  <name>Task 3: Create Alembic migrations</name>
  <files>
    alembic.ini
    alembic/env.py
    alembic/script.py.mako
    alembic/versions/001_initial_schema.py
  </files>
  <action>
Set up Alembic migrations with initial schema:

1. **alembic.ini** (root of project):
   ```ini
   [alembic]
   script_location = alembic
   prepend_sys_path = .
   version_path_separator = os

   [post_write_hooks]

   [loggers]
   keys = root,sqlalchemy,alembic

   [handlers]
   keys = console

   [formatters]
   keys = generic

   [logger_root]
   level = WARN
   handlers = console

   [logger_sqlalchemy]
   level = WARN
   handlers =
   qualname = sqlalchemy.engine

   [logger_alembic]
   level = INFO
   handlers =
   qualname = alembic

   [handler_console]
   class = StreamHandler
   args = (sys.stderr,)
   level = NOTSET
   formatter = generic

   [formatter_generic]
   format = %(levelname)-5.5s [%(name)s] %(message)s
   datefmt = %H:%M:%S
   ```

2. **alembic/env.py**:
   ```python
   """Alembic environment configuration."""
   import os
   from logging.config import fileConfig
   from sqlalchemy import engine_from_config, pool
   from alembic import context

   # Import metadata for autogenerate support
   from src.adapters.persistence.orm.base import metadata

   config = context.config

   # Set database URL from environment
   database_url = os.getenv(
       "DATABASE_URL",
       "postgresql://postgres:postgres@localhost:5432/finance"
   )
   config.set_main_option("sqlalchemy.url", database_url)

   if config.config_file_name is not None:
       fileConfig(config.config_file_name)

   target_metadata = metadata

   def run_migrations_offline() -> None:
       """Run migrations in 'offline' mode."""
       url = config.get_main_option("sqlalchemy.url")
       context.configure(
           url=url,
           target_metadata=target_metadata,
           literal_binds=True,
           dialect_opts={"paramstyle": "named"},
       )

       with context.begin_transaction():
           context.run_migrations()

   def run_migrations_online() -> None:
       """Run migrations in 'online' mode."""
       connectable = engine_from_config(
           config.get_section(config.config_ini_section, {}),
           prefix="sqlalchemy.",
           poolclass=pool.NullPool,
       )

       with connectable.connect() as connection:
           context.configure(
               connection=connection,
               target_metadata=target_metadata,
           )

           with context.begin_transaction():
               context.run_migrations()

   if context.is_offline_mode():
       run_migrations_offline()
   else:
       run_migrations_online()
   ```

3. **alembic/script.py.mako** (template for new migrations):
   ```mako
   """${message}

   Revision ID: ${up_revision}
   Revises: ${down_revision | comma,n}
   Create Date: ${create_date}
   """
   from typing import Sequence, Union
   from alembic import op
   import sqlalchemy as sa
   ${imports if imports else ""}

   revision: str = ${repr(up_revision)}
   down_revision: Union[str, None] = ${repr(down_revision)}
   branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
   depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


   def upgrade() -> None:
       ${upgrades if upgrades else "pass"}


   def downgrade() -> None:
       ${downgrades if downgrades else "pass"}
   ```

4. **alembic/versions/001_initial_schema.py**:
   ```python
   """Initial schema with outbox, users, and encrypted_secrets.

   Revision ID: 001
   Revises:
   Create Date: 2026-01-29
   """
   from typing import Sequence, Union
   from alembic import op
   import sqlalchemy as sa

   revision: str = "001"
   down_revision: Union[str, None] = None
   branch_labels: Union[str, Sequence[str], None] = None
   depends_on: Union[str, Sequence[str], None] = None


   def upgrade() -> None:
       # Outbox table for domain events
       op.create_table(
           "outbox",
           sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
           sa.Column("event_type", sa.String(length=255), nullable=False),
           sa.Column("aggregate_type", sa.String(length=255), nullable=False),
           sa.Column("aggregate_id", sa.String(length=36), nullable=False),
           sa.Column("payload", sa.Text(), nullable=False),
           sa.Column("created_at", sa.DateTime(timezone=True), nullable=False),
           sa.Column("processed_at", sa.DateTime(timezone=True), nullable=True),
           sa.PrimaryKeyConstraint("id", name=op.f("pk_outbox")),
       )
       op.create_index(
           op.f("ix_outbox_unprocessed"),
           "outbox",
           ["processed_at"],
           unique=False,
           postgresql_where=sa.text("processed_at IS NULL"),
       )

       # Users table
       op.create_table(
           "users",
           sa.Column("id", sa.String(length=36), nullable=False),
           sa.Column("email", sa.String(length=255), nullable=False),
           sa.Column("email_verified", sa.Boolean(), nullable=False, server_default="false"),
           sa.Column("created_at", sa.DateTime(timezone=True), nullable=False),
           sa.Column("updated_at", sa.DateTime(timezone=True), nullable=False),
           sa.PrimaryKeyConstraint("id", name=op.f("pk_users")),
           sa.UniqueConstraint("email", name=op.f("uq_users_email")),
       )

       # Encrypted secrets storage
       op.create_table(
           "encrypted_secrets",
           sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
           sa.Column("user_id", sa.String(length=36), nullable=False),
           sa.Column("secret_type", sa.String(length=50), nullable=False),
           sa.Column("encrypted_value", sa.Text(), nullable=False),
           sa.Column("created_at", sa.DateTime(timezone=True), nullable=False),
           sa.Column("updated_at", sa.DateTime(timezone=True), nullable=False),
           sa.ForeignKeyConstraint(
               ["user_id"],
               ["users.id"],
               name=op.f("fk_encrypted_secrets_user_id_users"),
           ),
           sa.PrimaryKeyConstraint("id", name=op.f("pk_encrypted_secrets")),
       )
       op.create_index(
           op.f("ix_encrypted_secrets_user_type"),
           "encrypted_secrets",
           ["user_id", "secret_type"],
           unique=True,
       )


   def downgrade() -> None:
       op.drop_table("encrypted_secrets")
       op.drop_table("users")
       op.drop_index(op.f("ix_outbox_unprocessed"), table_name="outbox")
       op.drop_table("outbox")
   ```
  </action>
  <verify>
    - `ls alembic/versions/` shows 001_initial_schema.py
    - `grep "outbox" alembic/versions/001_initial_schema.py` shows outbox table creation
    - `cat alembic.ini | grep "script_location"` shows alembic config
  </verify>
  <done>
    - Alembic configuration complete
    - Initial migration creates outbox, users, encrypted_secrets tables
    - Migration can run on fresh PostgreSQL database
    - Proper naming conventions for constraints and indexes
  </done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Verify table definitions are valid Python:
   ```bash
   python -c "from src.adapters.persistence.orm.tables import outbox, users, encrypted_secrets; print('Tables OK')"
   ```

2. Verify UoW imports correctly:
   ```bash
   python -c "from src.adapters.persistence.unit_of_work import SqlAlchemyUnitOfWork; print('UoW OK')"
   ```

3. Verify domain layer still has no infrastructure imports:
   ```bash
   grep -r "from sqlalchemy\|from fastapi\|from pydantic" src/domain/
   # Should return nothing
   ```

4. Run import-linter to verify architecture:
   ```bash
   lint-imports
   ```
</verification>

<success_criteria>
- [ ] Table definitions exist for outbox, users, encrypted_secrets
- [ ] Imperative mapping infrastructure ready for future entities
- [ ] Unit of Work collects events and writes to outbox on commit
- [ ] Alembic config and initial migration created
- [ ] Migration creates all tables with proper constraints
- [ ] Domain layer has ZERO SQLAlchemy imports
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-04-SUMMARY.md` with:
- Tables created and their purposes
- UoW and mapping patterns implemented
- Migration structure
- Commands to run migrations
</output>
